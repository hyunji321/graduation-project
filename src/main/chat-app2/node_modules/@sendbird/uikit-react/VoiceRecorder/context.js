import React__default, { useState, useEffect, useCallback, useContext, createContext } from 'react';
import { B as BROWSER_SUPPORT_MIME_TYPE_LIST, h as VOICE_RECORDER_AUDIO_BITS, b as VOICE_MESSAGE_FILE_NAME, c as VOICE_MESSAGE_MIME_TYPE } from '../consts-95d8566e.js';
import useSendbirdStateContext from '../useSendbirdStateContext.js';
import '../withSendbird.js';
import '../_rollupPluginBabelHelpers-6bb0305c.js';

// Input props of VoiceRecorder

// Output of VoiceRecorder

const noop = () => {/* noop */};
const Context = /*#__PURE__*/createContext({
  start: noop,
  stop: noop,
  isRecordable: false
});
const VoiceRecorderProvider = props => {
  var _BROWSER_SUPPORT_MIME;
  const {
    children
  } = props;
  const {
    config
  } = useSendbirdStateContext();
  const {
    logger,
    isVoiceMessageEnabled
  } = config;
  const [mediaRecorder, setMediaRecorder] = useState(null);
  const [isRecordable, setIsRecordable] = useState(false);
  const browserSupportMimeType = (_BROWSER_SUPPORT_MIME = BROWSER_SUPPORT_MIME_TYPE_LIST.find(mimeType => MediaRecorder.isTypeSupported(mimeType))) !== null && _BROWSER_SUPPORT_MIME !== void 0 ? _BROWSER_SUPPORT_MIME : '';
  if (!browserSupportMimeType) {
    logger.error('VoiceRecorder: Browser does not support mimeType', {
      mimmeTypes: BROWSER_SUPPORT_MIME_TYPE_LIST
    });
  }
  const [webAudioUtils, setWebAudioUtils] = useState(null);
  useEffect(() => {
    if (isVoiceMessageEnabled && !webAudioUtils) {
      import('../WebAudioUtils-6df19fcc.js').then(data => {
        setWebAudioUtils(data);
      });
    }
  }, []);
  const start = useCallback(eventHandler => {
    var _navigator, _navigator$mediaDevic, _navigator$mediaDevic2;
    if (isVoiceMessageEnabled && !webAudioUtils) {
      logger.error('VoiceRecorder: Recording audio processor is being loaded.');
      return;
    }
    logger.info('VoiceRecorder: Start recording.');
    if (mediaRecorder) {
      stop();
      logger.info('VoiceRecorder: Previous mediaRecorder is stopped.');
    }
    (_navigator = navigator) === null || _navigator === void 0 ? void 0 : (_navigator$mediaDevic = _navigator.mediaDevices) === null || _navigator$mediaDevic === void 0 ? void 0 : (_navigator$mediaDevic2 = _navigator$mediaDevic.getUserMedia) === null || _navigator$mediaDevic2 === void 0 ? void 0 : _navigator$mediaDevic2.call(_navigator$mediaDevic, {
      audio: true
    }).then(stream => {
      logger.info('VoiceRecorder: Succeeded getting media stream.', stream);
      setIsRecordable(true);
      const mediaRecorder = new MediaRecorder(stream, {
        mimeType: browserSupportMimeType,
        audioBitsPerSecond: VOICE_RECORDER_AUDIO_BITS
      });
      mediaRecorder.ondataavailable = e => {
        var _stream$getAudioTrack, _stream$getAudioTrack2, _stream$getAudioTrack3;
        // when recording stops
        logger.info('VoiceRecorder: Succeeded getting an available data.', e.data);
        const audioFile = new File([e.data], VOICE_MESSAGE_FILE_NAME, {
          lastModified: new Date().getTime(),
          type: VOICE_MESSAGE_MIME_TYPE
        });
        webAudioUtils === null || webAudioUtils === void 0 ? void 0 : webAudioUtils.downsampleToWav(audioFile, buffer => {
          const mp3Buffer = webAudioUtils === null || webAudioUtils === void 0 ? void 0 : webAudioUtils.encodeMp3(buffer);
          const mp3blob = new Blob(mp3Buffer, {
            type: VOICE_MESSAGE_MIME_TYPE
          });
          const convertedAudioFile = new File([mp3blob], VOICE_MESSAGE_FILE_NAME, {
            lastModified: new Date().getTime(),
            type: VOICE_MESSAGE_MIME_TYPE
          });
          eventHandler === null || eventHandler === void 0 ? void 0 : eventHandler.onRecordingEnded(convertedAudioFile);
          logger.info('VoiceRecorder: Succeeded converting audio file.', convertedAudioFile);
        });
        stream === null || stream === void 0 ? void 0 : (_stream$getAudioTrack = stream.getAudioTracks) === null || _stream$getAudioTrack === void 0 ? void 0 : (_stream$getAudioTrack2 = (_stream$getAudioTrack3 = _stream$getAudioTrack.call(stream)).forEach) === null || _stream$getAudioTrack2 === void 0 ? void 0 : _stream$getAudioTrack2.call(_stream$getAudioTrack3, track => track === null || track === void 0 ? void 0 : track.stop());
        setIsRecordable(false);
      };
      mediaRecorder === null || mediaRecorder === void 0 ? void 0 : mediaRecorder.start();
      setMediaRecorder(mediaRecorder);
      eventHandler === null || eventHandler === void 0 ? void 0 : eventHandler.onRecordingStarted();
    }).catch(err => {
      logger.error('VoiceRecorder: Failed getting media stream.', err);
      setMediaRecorder(null);
    });
  }, [mediaRecorder, webAudioUtils]);
  const stop = useCallback(() => {
    // Stop recording
    mediaRecorder === null || mediaRecorder === void 0 ? void 0 : mediaRecorder.stop();
    setMediaRecorder(null);
    setIsRecordable(false);
    logger.info('VoiceRecorder: Stop recording.');
  }, [mediaRecorder]);
  return /*#__PURE__*/React__default.createElement(Context.Provider, {
    value: {
      start,
      stop,
      isRecordable
    }
  }, children);
};
const useVoiceRecorderContext = () => useContext(Context);
var index = {
  VoiceRecorderProvider,
  useVoiceRecorderContext
};

export { VoiceRecorderProvider, index as default, useVoiceRecorderContext };
//# sourceMappingURL=context.js.map
