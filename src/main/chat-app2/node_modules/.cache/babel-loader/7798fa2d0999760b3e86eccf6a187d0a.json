{"ast":null,"code":"import { A as isUrl } from './index-7eb65acf.js';\nconst USER_MENTION_PREFIX = '@';\nconst TOKEN_TYPES = {\n  string: 'string',\n  mention: 'mention',\n  url: 'url',\n  undetermined: 'undetermined'\n};\nfunction getUserMentionRegex(mentionedUsers, templatePrefix_) {\n  const templatePrefix = templatePrefix_ || USER_MENTION_PREFIX;\n  return RegExp(`(${mentionedUsers.map(u => {\n    const userId = u.userId.replace(\n    // If user.id includes these patterns, need to convert it into an escaped one\n    /([.*+?^${}()|[\\]\\\\])/g, '\\\\$1');\n    /**\n     * //{ And //} are also for escaping\n     * because curly braces `{}` are metacharacters in regular expressions used to specify repetition\n     */\n    return `${templatePrefix}\\\\{${userId}\\\\}`;\n  }).join('|')})`, 'g');\n}\nfunction identifyMentions(_ref) {\n  let {\n    tokens,\n    mentionedUsers = [],\n    templatePrefix = USER_MENTION_PREFIX\n  } = _ref;\n  if (!(mentionedUsers !== null && mentionedUsers !== void 0 && mentionedUsers.length)) {\n    return tokens;\n  }\n  const userMentionRegex = getUserMentionRegex(mentionedUsers, templatePrefix);\n  const results = tokens.map(token => {\n    // if the token is not undetermined, return it as is\n    // is kinda unnecessary with TS, but just in case\n    if (token.type !== TOKEN_TYPES.undetermined) {\n      return token;\n    }\n    const {\n      value\n    } = token;\n    const parts = value.split(userMentionRegex);\n    const tokens = parts.map(part => {\n      if (part.match(userMentionRegex)) {\n        const matchedUser = mentionedUsers.find(user => `@{${user === null || user === void 0 ? void 0 : user.userId}}` === part);\n        const nickname = (matchedUser === null || matchedUser === void 0 ? void 0 : matchedUser.nickname) || '(No name)';\n        return {\n          value: nickname,\n          type: TOKEN_TYPES.mention,\n          userId: matchedUser === null || matchedUser === void 0 ? void 0 : matchedUser.userId\n        };\n      } else {\n        return {\n          value: part,\n          type: TOKEN_TYPES.undetermined\n        };\n      }\n    });\n    return tokens;\n  }).flat();\n  return results;\n}\nfunction identifyUrlsAndStrings(token) {\n  const results = token.map(token => {\n    if (token.type !== TOKEN_TYPES.undetermined) {\n      return token;\n    }\n    const {\n      value = ''\n    } = token;\n    const parts = value.split(' ');\n    const tokens = parts.map(part => {\n      if (isUrl(part)) {\n        return {\n          value: part,\n          type: TOKEN_TYPES.url\n        };\n      } else {\n        return {\n          value: part,\n          type: TOKEN_TYPES.string\n        };\n      }\n    });\n    return tokens;\n  }).flat();\n  return results;\n}\nfunction combineNearbyStrings(tokens) {\n  const results = tokens.reduce((acc, token) => {\n    const lastToken = acc[acc.length - 1];\n    if ((lastToken === null || lastToken === void 0 ? void 0 : lastToken.type) === TOKEN_TYPES.string && token.type === TOKEN_TYPES.string) {\n      lastToken.value = `${lastToken.value} ${token.value}`;\n      return acc;\n    }\n    return [...acc, token];\n  }, []);\n  return results;\n}\n\n/**\n * Converts text into set of rich tokens\n */\nfunction tokenizeMessage(_ref2) {\n  let {\n    messageText,\n    mentionedUsers = [],\n    templatePrefix = USER_MENTION_PREFIX\n  } = _ref2;\n  // mention can be squeezed-in(no-space-between) with other mentions and urls\n  // if no users are mentioned, return the messageText as a single token\n  const partialResult = [{\n    type: TOKEN_TYPES.undetermined,\n    value: messageText\n  }];\n\n  // order is important because we want to identify mentions first\n  // identifyMentions will return a token with type mention or undetermined\n  const partialWithMentions = identifyMentions({\n    tokens: partialResult,\n    mentionedUsers,\n    templatePrefix\n  });\n  const partialsWithUrlsAndMentions = identifyUrlsAndStrings(partialWithMentions);\n  const result = combineNearbyStrings(partialsWithUrlsAndMentions);\n  return result;\n}\n\n/**\n * Don't need to use this util in DOM element since the white spaces will be kept as is,\n * but will need if the text is wrapped \\w React.Fragement or </>\n * @link https://sendbird.slack.com/archives/GPGHESTL3/p1681180484341369\n * Or!!! -> convert any space or tab in leading/trailing to nbsp\n * to preserve the leading & trailing white spaces\n */\nfunction getWhiteSpacePreservedText(text) {\n  const NON_BREAKING_SPACE = '\\u00A0';\n  // Split the input string into lines\n  const lines = text.split('\\n');\n\n  // Process each line and convert leading and trailing white spaces to \"\\u00A0\"\n  const processedLines = lines.map(line => {\n    var _line$match, _line$match2;\n    const leadingWhitespace = ((_line$match = line.match(/^\\s*/)) === null || _line$match === void 0 ? void 0 : _line$match[0]) || '';\n    const trailingWhitespace = ((_line$match2 = line.match(/\\s*$/)) === null || _line$match2 === void 0 ? void 0 : _line$match2[0]) || '';\n    const convertedLeadingWhitespace = leadingWhitespace.replace(/ /g, NON_BREAKING_SPACE);\n    const convertedTrailingWhitespace = trailingWhitespace.replace(/ /g, NON_BREAKING_SPACE);\n    return convertedLeadingWhitespace + line.trim() + convertedTrailingWhitespace;\n  });\n\n  // Combine the processed lines into a new string with \"\\n\"\n  const result = processedLines.join('\\n');\n  return result;\n}\nexport { TOKEN_TYPES as T, USER_MENTION_PREFIX as U, getWhiteSpacePreservedText as g, tokenizeMessage as t };","map":{"version":3,"mappings":";AAAO,MAAMA,mBAAmB,GAAG;ACG5B,MAAMC,WAAW,GAAG;EACzBC,MAAM,EAAE,QAAQ;EAChBC,OAAO,EAAE,SAAS;EAClBC,GAAG,EAAE,KAAK;EACVC,YAAY,EAAE;AAChB;ACHO,SAASC,mBAAmBA,CAACC,cAAsB,EAAEC,eAAuB,EAAU;EAC3F,MAAMC,cAAc,GAAGD,eAAe,IAAIR,mBAAmB;EAE7D,OAAOU,MAAM,CAAKH,kBAAc,CAACI,GAAG,CAACC,CAAC,IAAI;IACxC,MAAMC,MAAM,GAAGD,CAAC,CAACC,MAAM,CAACC,OAAO;IAC7B;IACA,uBAAuB,EACvB,MAAM,CAAC;IACP;AACN;AACA;AACA;IACI,OAAUL,iBAAoBI,YAAW;GAC1C,CAAC,CAACE,IAAI,CAAC,GAAG,CAAE,GAAE,EAAE,GAAG,CAAC;AACvB;AAEO,SAASC,gBAAgBA,OAI+B;EAAA,IAJ9B;IAC/BC,MAAM;IACNV,cAAc,GAAG,EAAE;IACnBE,cAAc,GAAGT;EACG,CAAC;EACrB,IAAI,EAACO,cAAc,KAAdA,sBAAc,eAAdA,cAAc,CAAEW,MAAM,CAAE;IAC3B,OAAOD,MAAM;EACf;EACA,MAAME,gBAAgB,GAAGb,mBAAmB,CAACC,cAAc,EAAEE,cAAc,CAAC;EAC5E,MAAMW,OAA6C,GAAGH,MAAM,CAACN,GAAG,CAAEU,KAAK,IAAK;IAC1E;IACA;IACA,IAAIA,KAAK,CAACC,IAAI,KAAKrB,WAAW,CAACI,YAAY,EAAE;MAC3C,OAAOgB,KAAK;IACd;IACA,MAAM;MAAEE;IAAM,CAAC,GAAGF,KAAK;IACvB,MAAMG,KAAK,GAAGD,KAAK,CAACE,KAAK,CAACN,gBAAgB,CAAC;IAE3C,MAAMF,MAAM,GAAGO,KAAK,CAACb,GAAG,CAAEe,IAAI,IAAK;MACjC,IAAIA,IAAI,CAACC,KAAK,CAACR,gBAAgB,CAAC,EAAE;QAChC,MAAMS,WAAW,GAAGrB,cAAc,CAACsB,IAAI,CAAEC,IAAI,IAAM,KAAIA,IAAI,KAAJA,YAAI,uBAAJA,IAAI,CAAEjB,MAAS,QAAKa,IAAI,CAAC;QAChF,MAAMK,QAAQ,GAAG,YAAW,aAAXH,WAAW,uBAAXA,WAAW,CAAEG,QAAQ,KAAI,WAAW;QACrD,OAAO;UAAER,KAAK,EAAEQ,QAAQ;UAAET,IAAI,EAAErB,WAAW,CAACE,OAAO;UAAEU,MAAM,EAAEe,WAAW,aAAXA,WAAW,uBAAXA,WAAW,CAAEf;SAAQ;MACpF,CAAC,MAAM;QACL,OAAO;UAAEU,KAAK,EAAEG,IAAI;UAAEJ,IAAI,EAAErB,WAAW,CAACI;SAAc;MACxD;IACF,CAAC,CAAC;IACF,OAAOY,MAAM;GACd,CAAC,CAACe,IAAI,EAAE;EACT,OAAOZ,OAAO;AAChB;AAEO,SAASa,sBAAsBA,CAACZ,KAAc,EAAW;EAC9D,MAAMD,OAAgB,GAAGC,KAAK,CAACV,GAAG,CAAEU,KAAK,IAAK;IAC5C,IAAIA,KAAK,CAACC,IAAI,KAAKrB,WAAW,CAACI,YAAY,EAAE;MAC3C,OAAOgB,KAAK;IACd;IACA,MAAM;MAAEE,KAAK,GAAG;IAAG,CAAC,GAAGF,KAAK;IAC5B,MAAMG,KAAK,GAAGD,KAAK,CAACE,KAAK,CAAC,GAAG,CAAC;IAC9B,MAAMR,MAAM,GAAGO,KAAK,CAACb,GAAG,CAAEe,IAAI,IAAK;MACjC,IAAIQ,KAAK,CAACR,IAAI,CAAC,EAAE;QACf,OAAO;UAAEH,KAAK,EAAEG,IAAI;UAAEJ,IAAI,EAAErB,WAAW,CAACG;SAAK;MAC/C,CAAC,MAAM;QACL,OAAO;UAAEmB,KAAK,EAAEG,IAAI;UAAEJ,IAAI,EAAErB,WAAW,CAACC;SAAQ;MAClD;IACF,CAAC,CAAC;IACF,OAAOe,MAAM;GACd,CAAC,CAACe,IAAI,EAAE;EAET,OAAOZ,OAAO;AAChB;AAEO,SAASe,oBAAoBA,CAAClB,MAAe,EAAW;EAC7D,MAAMG,OAAgB,GAAGH,MAAM,CAACmB,MAAM,CAAC,CAACC,GAAG,EAAEhB,KAAK,KAAK;IACrD,MAAMiB,SAAS,GAAGD,GAAG,CAACA,GAAG,CAACnB,MAAM,GAAG,CAAC,CAAC;IACrC,IAAI,UAAS,KAAToB,iBAAS,uBAATA,SAAS,CAAEhB,IAAI,MAAKrB,WAAW,CAACC,MAAM,IAAImB,KAAK,CAACC,IAAI,KAAKrB,WAAW,CAACC,MAAM,EAAE;MAC/EoC,SAAS,CAACf,KAAK,GAAMe,YAAS,CAACf,KAASF,SAAK,CAACE,KAAO;MACrD,OAAOc,GAAG;IACZ;IACA,OAAO,CAAC,GAAGA,GAAG,EAAEhB,KAAK,CAAC;GACvB,EAAE,EAAE,CAAC;EACN,OAAOD,OAAO;AAChB;;AAEA;AACA;AACA;AACO,SAASmB,eAAeA,QAIN;EAAA,IAJO;IAC9BC,WAAW;IACXjC,cAAc,GAAG,EAAE;IACnBE,cAAc,GAAGT;EACN,CAAC;EACZ;EACA;EACA,MAAMyC,aAAa,GAAG,CAAC;IACrBnB,IAAI,EAAErB,WAAW,CAACI,YAAY;IAC9BkB,KAAK,EAAEiB;EACT,CAAC,CAAC;;EAEF;EACA;EACA,MAAME,mBAAmB,GAAG1B,gBAAgB,CAAC;IAC3CC,MAAM,EAAEwB,aAAa;IACrBlC,cAAc;IACdE;EACF,CAAC,CAAC;EACF,MAAMkC,2BAA2B,GAAGV,sBAAsB,CAACS,mBAAmB,CAAC;EAC/E,MAAME,MAAM,GAAGT,oBAAoB,CAACQ,2BAA2B,CAAC;EAEhE,OAAOC,MAAM;AACf;;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;AACO,SAASC,0BAA0BA,CAACC,IAAY,EAAU;EAC/D,MAAMC,kBAAkB,GAAG,QAAQ;EACnC;EACA,MAAMC,KAAK,GAAGF,IAAI,CAACrB,KAAK,CAAC,IAAI,CAAC;;EAE9B;EACA,MAAMwB,cAAc,GAAGD,KAAK,CAACrC,GAAG,CAAEuC,IAAI,IAAK;IAAA;IACzC,MAAMC,iBAAiB,GAAG,oBAAI,CAACxB,KAAK,CAAC,MAAM,CAAC,8BAAlByB,8BAAqB,CAAC,CAAC,KAAI,EAAE;IACvD,MAAMC,kBAAkB,GAAG,qBAAI,CAAC1B,KAAK,CAAC,MAAM,CAAC,+BAAlB2B,+BAAqB,CAAC,CAAC,KAAI,EAAE;IAExD,MAAMC,0BAA0B,GAAGJ,iBAAiB,CAACrC,OAAO,CAAC,IAAI,EAAEiC,kBAAkB,CAAC;IACtF,MAAMS,2BAA2B,GAAGH,kBAAkB,CAACvC,OAAO,CAAC,IAAI,EAAEiC,kBAAkB,CAAC;IAExF,OAAOQ,0BAA0B,GAAGL,IAAI,CAACO,IAAI,EAAE,GAAGD,2BAA2B;EAC/E,CAAC,CAAC;;EAEF;EACA,MAAMZ,MAAM,GAAGK,cAAc,CAAClC,IAAI,CAAC,IAAI,CAAC;EAExC,OAAO6B,MAAM;AACf","names":["USER_MENTION_PREFIX","TOKEN_TYPES","string","mention","url","undetermined","getUserMentionRegex","mentionedUsers","templatePrefix_","templatePrefix","RegExp","map","u","userId","replace","join","identifyMentions","tokens","length","userMentionRegex","results","token","type","value","parts","split","part","match","matchedUser","find","user","nickname","flat","identifyUrlsAndStrings","isUrl","combineNearbyStrings","reduce","acc","lastToken","tokenizeMessage","messageText","partialResult","partialWithMentions","partialsWithUrlsAndMentions","result","getWhiteSpacePreservedText","text","NON_BREAKING_SPACE","lines","processedLines","line","leadingWhitespace","_line$match","trailingWhitespace","_line$match2","convertedLeadingWhitespace","convertedTrailingWhitespace","trim"],"sources":["C:\\Users\\이경민\\IdeaProjects\\sendbird-uikit-whatsapp-sample\\node_modules\\@sendbird\\src\\modules\\Message\\consts.ts","C:\\Users\\이경민\\IdeaProjects\\sendbird-uikit-whatsapp-sample\\node_modules\\@sendbird\\src\\modules\\Message\\utils\\tokens\\types.ts","C:\\Users\\이경민\\IdeaProjects\\sendbird-uikit-whatsapp-sample\\node_modules\\@sendbird\\src\\modules\\Message\\utils\\tokens\\tokenize.ts"],"sourcesContent":["export const USER_MENTION_PREFIX = '@';\n","import { User } from '@sendbird/chat';\nimport { ObjectValues } from '../../../../utils/typeHelpers/objectValues';\n\nexport const TOKEN_TYPES = {\n  string: 'string',\n  mention: 'mention',\n  url: 'url',\n  undetermined: 'undetermined',\n} as const;\n\nexport type TokenType = ObjectValues<typeof TOKEN_TYPES>;\n\nexport type StringToken = {\n  type: typeof TOKEN_TYPES.string;\n  value: string;\n};\n\nexport type MentionToken = {\n  type: TokenType;\n  value: string;\n  userId: string;\n};\n\nexport type UrlToken = {\n  type: typeof TOKEN_TYPES.url;\n  value: string;\n};\n\nexport type UndeterminedToken = {\n  type: typeof TOKEN_TYPES.undetermined;\n  value: string;\n};\n\nexport type Token = StringToken | MentionToken | UrlToken | UndeterminedToken;\n\nexport type TokenParams = {\n  messageText: string;\n  mentionedUsers?: User[];\n  templatePrefix?: string;\n};\n\nexport type IdentifyMentionsType = {\n  tokens: UndeterminedToken[];\n  mentionedUsers: User[];\n  templatePrefix: string;\n};\n","import { User } from '@sendbird/chat';\nimport { USER_MENTION_PREFIX } from '../../consts';\nimport { IdentifyMentionsType, MentionToken, Token, TOKEN_TYPES, TokenParams, UndeterminedToken } from './types';\nimport { isUrl } from '../../../../utils';\n\nexport function getUserMentionRegex(mentionedUsers: User[], templatePrefix_: string): RegExp {\n  const templatePrefix = templatePrefix_ || USER_MENTION_PREFIX;\n\n  return RegExp(`(${mentionedUsers.map(u => {\n    const userId = u.userId.replace(\n      // If user.id includes these patterns, need to convert it into an escaped one\n      /([.*+?^${}()|[\\]\\\\])/g,\n      '\\\\$1');\n      /**\n       * //{ And //} are also for escaping\n       * because curly braces `{}` are metacharacters in regular expressions used to specify repetition\n       */\n    return `${templatePrefix}\\\\{${userId}\\\\}`;\n  }).join('|')})`, 'g');\n}\n\nexport function identifyMentions({\n  tokens,\n  mentionedUsers = [],\n  templatePrefix = USER_MENTION_PREFIX,\n}: IdentifyMentionsType): (MentionToken | UndeterminedToken)[] {\n  if (!mentionedUsers?.length) {\n    return tokens;\n  }\n  const userMentionRegex = getUserMentionRegex(mentionedUsers, templatePrefix);\n  const results: (UndeterminedToken | MentionToken)[] = tokens.map((token) => {\n    // if the token is not undetermined, return it as is\n    // is kinda unnecessary with TS, but just in case\n    if (token.type !== TOKEN_TYPES.undetermined) {\n      return token;\n    }\n    const { value } = token;\n    const parts = value.split(userMentionRegex);\n\n    const tokens = parts.map((part) => {\n      if (part.match(userMentionRegex)) {\n        const matchedUser = mentionedUsers.find((user) => `@{${user?.userId}}` === part);\n        const nickname = matchedUser?.nickname || '(No name)';\n        return { value: nickname, type: TOKEN_TYPES.mention, userId: matchedUser?.userId };\n      } else {\n        return { value: part, type: TOKEN_TYPES.undetermined };\n      }\n    });\n    return tokens;\n  }).flat();\n  return results;\n}\n\nexport function identifyUrlsAndStrings(token: Token[]): Token[] {\n  const results: Token[] = token.map((token) => {\n    if (token.type !== TOKEN_TYPES.undetermined) {\n      return token;\n    }\n    const { value = '' } = token;\n    const parts = value.split(' ');\n    const tokens = parts.map((part) => {\n      if (isUrl(part)) {\n        return { value: part, type: TOKEN_TYPES.url };\n      } else {\n        return { value: part, type: TOKEN_TYPES.string };\n      }\n    });\n    return tokens;\n  }).flat();\n\n  return results;\n}\n\nexport function combineNearbyStrings(tokens: Token[]): Token[] {\n  const results: Token[] = tokens.reduce((acc, token) => {\n    const lastToken = acc[acc.length - 1];\n    if (lastToken?.type === TOKEN_TYPES.string && token.type === TOKEN_TYPES.string) {\n      lastToken.value = `${lastToken.value} ${token.value}`;\n      return acc;\n    }\n    return [...acc, token];\n  }, []);\n  return results;\n}\n\n/**\n * Converts text into set of rich tokens\n */\nexport function tokenizeMessage({\n  messageText,\n  mentionedUsers = [],\n  templatePrefix = USER_MENTION_PREFIX,\n}: TokenParams): Token[] {\n  // mention can be squeezed-in(no-space-between) with other mentions and urls\n  // if no users are mentioned, return the messageText as a single token\n  const partialResult = [{\n    type: TOKEN_TYPES.undetermined,\n    value: messageText,\n  }];\n\n  // order is important because we want to identify mentions first\n  // identifyMentions will return a token with type mention or undetermined\n  const partialWithMentions = identifyMentions({\n    tokens: partialResult,\n    mentionedUsers,\n    templatePrefix,\n  });\n  const partialsWithUrlsAndMentions = identifyUrlsAndStrings(partialWithMentions);\n  const result = combineNearbyStrings(partialsWithUrlsAndMentions);\n\n  return result;\n}\n\n/**\n * Don't need to use this util in DOM element since the white spaces will be kept as is,\n * but will need if the text is wrapped \\w React.Fragement or </>\n * @link https://sendbird.slack.com/archives/GPGHESTL3/p1681180484341369\n * Or!!! -> convert any space or tab in leading/trailing to nbsp\n * to preserve the leading & trailing white spaces\n */\nexport function getWhiteSpacePreservedText(text: string): string {\n  const NON_BREAKING_SPACE = '\\u00A0';\n  // Split the input string into lines\n  const lines = text.split('\\n');\n\n  // Process each line and convert leading and trailing white spaces to \"\\u00A0\"\n  const processedLines = lines.map((line) => {\n    const leadingWhitespace = line.match(/^\\s*/)?.[0] || '';\n    const trailingWhitespace = line.match(/\\s*$/)?.[0] || '';\n\n    const convertedLeadingWhitespace = leadingWhitespace.replace(/ /g, NON_BREAKING_SPACE);\n    const convertedTrailingWhitespace = trailingWhitespace.replace(/ /g, NON_BREAKING_SPACE);\n\n    return convertedLeadingWhitespace + line.trim() + convertedTrailingWhitespace;\n  });\n\n  // Combine the processed lines into a new string with \"\\n\"\n  const result = processedLines.join('\\n');\n\n  return result;\n}\n"]},"metadata":{},"sourceType":"module"}